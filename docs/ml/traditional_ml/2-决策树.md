# 二、决策树

决策树算法是一种基于树形结构的监督学习算法。它通过对训练数据集进行递归的分割，生成一个树形结构，用于对新的输入数据进行分类或回归。

香农熵（Shannon entropy）是一种用于度量随机事件的不确定性或信息量的指标。它是由美国数学家克劳德·香农（Claude Shannon）在1948年提出的，被认为是信息论的基础。

香农熵通常用来表示一个随机事件或一个信源的平均信息量，它的计算方式是将事件的每种可能性的信息量加起来并取平均值。在这里，“信息量”指的是一个事件所提供的信息量大小，通常用该事件发生的概率的负对数来衡量。

具体来说，如果一个事件发生的概率是p，那么它的信息量就是-log2(p)。而香农熵就是将每种可能性的信息量加起来并取平均值，即H=-Σp(x)log2p(x)，其中x是事件的每种可能性，p(x)是该事件发生的概率。

香农熵越大，表示随机事件的不确定性越高，提供的信息量也就越大。反之，香农熵越小，表示随机事件的不确定性越小，提供的信息量也就越少。

## 1、算法步骤

决策树学习通常包括 3 个步骤: 特征选择、决策树的生成和决策树的修剪。

## 2、算法特点

决策树算法简单易懂，可解释性强，能够自动处理缺失值和异常值，但也存在过拟合、泛化能力差等问题，需要在实际应用中进行优化和改进。

## 3、sklearn 中的决策树

### (1) 鸢尾花

```python
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# 加载数据集
iris = load_iris()
X = iris.data
y = iris.target

# 将数据集划分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 创建决策树分类器
clf = DecisionTreeClassifier()

# 训练分类器
clf.fit(X_train, y_train)

# 对测试集进行预测
y_pred = clf.predict(X_test)

# 计算分类器的准确率
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
```

### (2) 隐形眼镜

#### 1. 项目概述和数据集概述

隐形眼镜类型包括硬材质、软材质以及不适合佩戴隐形眼镜。我们需要使用决策树预测患者需要佩戴的隐形眼镜类型。
数据集如下：

```
young	myope	no	reduced	no lenses
young	myope	no	normal	soft
young	myope	yes	reduced	no lenses
young	myope	yes	normal	hard
```

#### 2. 具体代码

```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score


def file2matrix(filename):
    """
    读取文本文件，返回特征矩阵和标签向量
    :param filename: 文件路径
    :return:特征矩阵和标签向量
    """
    # 加载隐形眼镜相关的 文本文件 数据
    fr = open(filename)
    # 标签向量
    labels = []
    label_mapping = {"no lenses": 0, "soft": 1, "hard": 2}
    # 特征描述与离散值的映射
    feature_mapping = [
        {"young": 0, "pre": 1, "presbyopic": 2},
        {"myope": 0, "hyper": 1},
        {"yes": 0, "no": 1},
        {"reduced": 0, "normal": 1}
    ]
    # 特征矩阵
    features = []
    for line in fr.readlines():
        # 该行的特征向量
        feature_in_line = []
        features_and_labels = line.strip().split('\t')
        labels.append(label_mapping[features_and_labels[-1]])
        for i in range(len(features_and_labels) - 1):
            feature_in_line.append(feature_mapping[i][features_and_labels[i]])
        features.append(feature_in_line)
    return features, labels


def create_data_set():
    """
    创建虚拟数据集
    :return:
    """
    data_set = [[1, 1, 1],
                [1, 1, 1],
                [1, 0, 1],
                [0, 1, 0],
                [0, 1, 0]]
    labels = [1, 1, 1, 0, 0]
    return data_set, labels


if __name__ == "__main__":
    # 加载数据集
    X, y = file2matrix('./data/lenses.txt')
    # X, y = create_data_set()

    # 将数据集划分为训练集和测试集
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    # 创建决策树分类器
    clf = DecisionTreeClassifier()

    # 训练分类器
    clf.fit(X_train, y_train)

    # 对测试集进行预测
    y_pred = clf.predict(X_test)

    # 计算分类器的准确率
    accuracy = accuracy_score(y_test, y_pred)
    print("Accuracy:", accuracy)
```
